{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf_dtype = tf.dtypes.float32\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "from lioness import Lioness\n",
    "from panda import Panda\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import utils\n",
    "#utils.set_random_seed(1)\n",
    "\n",
    "from NOTEARS import NOTEARS\n",
    "from ContextualNOTEARS import ContextualNOTEARS\n",
    "from LowRankContextualNOTEARS import LRContextualNOTEARS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(data_params):\n",
    "    if data_params[\"use_archetypes\"]:\n",
    "        W_dict, C_dict = dataloader.gen_archetypes(data_params[\"d\"], data_params[\"n_edges\"],\n",
    "                                                         data_params[\"n_c\"], data_params[\"k_true\"],\n",
    "                                                         graph_type=data_params[\"graph_type\"],\n",
    "                                                         ensure_convex=data_params[\"ensure_convex\"])\n",
    "        sample_loadings, W, C, X = dataloader.gen_samples(\n",
    "            W_dict, C_dict, n=data_params[\"n\"], n_i=data_params[\"n_i\"], n_mix=data_params[\"n_mix\"],\n",
    "            sem_type=data_params[\"sem_type\"])\n",
    "        for i in range(data_params[\"n_c\"]):\n",
    "            C[:, i] += np.random.normal(0.,\n",
    "                                        ((1-data_params[\"context_snr\"])/data_params[\"context_snr\"])*np.var(C[:, i]),\n",
    "                                        size=C[:, i].shape)\n",
    "    else:\n",
    "        W, C, X = dataloader.gen_samples_no_archs(data_params[\"n\"], data_params[\"d\"],\n",
    "                                                                  data_params[\"n_edges\"], data_params[\"n_i\"],\n",
    "                                                                  data_params[\"n_c\"], \n",
    "                                                                  c_signal_noise=data_params[\"context_snr\"],\n",
    "                                                                  graph_type=data_params[\"graph_type\"],\n",
    "                                                                  sem_type=data_params[\"sem_type\"])\n",
    "        W_dict, C_dict = None, None\n",
    "    return W, C, X, W_dict, C_dict\n",
    "\n",
    "def get_f1s(W_test, W_test_hat, threshs):\n",
    "    return [\n",
    "        np.mean([utils.f1_mat(W_test[i], W_test_hat[i], thresh, thresh) for i in range(len(W_test))])\n",
    "            for thresh in threshs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = [0.0, 0.001, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "def correlation_from_covariance(covariance):\n",
    "    v = np.sqrt(np.diag(covariance))\n",
    "    outer_v = np.outer(v, v)\n",
    "    correlation = covariance / outer_v\n",
    "    correlation[covariance == 0] = 0\n",
    "    return correlation\n",
    "\n",
    "\n",
    "\n",
    "# the below is redundant but kept for reference.  \n",
    "\n",
    "data_params = {\n",
    "    \"n\": 100,    # number of DAGs\n",
    "    \"n_i\": 1,     # number of samples per DAG\n",
    "    \"d\" : 16,       # number of vertices in each DAG\n",
    "    \"n_edges\": 4,     # expected number of edges in each DAG\n",
    "    \"n_c\": 8,    # number of contextual features\n",
    "    \"use_archetypes\": True,\n",
    "    \"ensure_convex\" : False, # should the archetype be generated such that they form a convex set of DAGs?\n",
    "    \"k_true\" : 2,       # number of true archetypes\n",
    "    \"graph_type\": \"ER\",\n",
    "    'sem_type' : 'gauss',\n",
    "    'context_snr' : 1.0, # signal-to-noise ratio of the contextual data\n",
    "    \"n_mix\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should all be the same as before\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Loading expression data ...\n",
      "  Elapsed time: 0.15 sec.\n",
      "Loading PPI data ...\n",
      "Number of PPIs: 238\n",
      "  Elapsed time: 0.16 sec.\n",
      "Calculating coexpression network ...\n",
      "  Elapsed time: 0.05 sec.\n",
      "Returning the correlation matrix of expression data in <Panda_obj>.correlation_matrix\n",
      "Loading input data ...\n",
      "  Elapsed time: 0.00 sec.\n",
      "(1000, 50)\n",
      "(100, 16)\n",
      "let's get this straight\n",
      "[[ 1.00000000e+00  4.01338605e-02  4.97832033e-01  5.04314703e-02\n",
      "  -2.28601882e-01  3.65281077e-02  3.42723079e-02  3.09459862e-02\n",
      "  -1.59635102e-01 -1.09800849e-01  1.63866377e-02 -2.54013540e-03\n",
      "  -1.00838723e-02 -5.52887041e-02  7.00147269e-01  1.72933594e-01]\n",
      " [ 4.01338605e-02  1.00000000e+00  5.11784853e-02  2.60316596e-02\n",
      "   1.15005690e-01 -3.01491394e-02  4.91558896e-02 -1.98787836e-03\n",
      "  -2.21534591e-01  1.43925217e-03  2.04708662e-02  5.71654378e-03\n",
      "   6.55544474e-03 -4.63618313e-02  4.67355284e-02  1.89290500e-01]\n",
      " [ 4.97832033e-01  5.11784853e-02  1.00000000e+00  5.40629453e-02\n",
      "  -7.93506077e-02  6.66549643e-02  1.58455409e-01  4.41139362e-01\n",
      "  -1.55700570e-01  1.23994725e-03  1.68233668e-01 -4.75864506e-03\n",
      "  -1.12071163e-01 -9.29674377e-02  4.09347085e-01  1.76028387e-01]\n",
      " [ 5.04314703e-02  2.60316596e-02  5.40629453e-02  1.00000000e+00\n",
      "  -1.09225055e-01 -1.61888434e-01  2.54397565e-02  1.85594822e-02\n",
      "   5.81939785e-02  1.42737780e-01 -1.51894397e-02 -5.48903359e-02\n",
      "  -2.19475084e-02 -3.00955414e-02  7.25766177e-02 -3.65409171e-02]\n",
      " [-2.28601882e-01  1.15005690e-01 -7.93506077e-02 -1.09225055e-01\n",
      "   1.00000000e+00 -1.25343156e-02 -6.25338849e-02  1.08301490e-01\n",
      "  -2.09624954e-01 -1.28338576e-02  3.64606888e-02  3.26891196e-02\n",
      "  -4.91237880e-02 -9.30913486e-02 -1.26728036e-01  1.68868098e-01]\n",
      " [ 3.65281077e-02 -3.01491394e-02  6.66549643e-02 -1.61888434e-01\n",
      "  -1.25343156e-02  1.00000000e+00 -1.50091291e-02  3.29314754e-02\n",
      "   2.38249571e-02 -2.66840046e-02 -1.25661380e-01  4.75272366e-02\n",
      "   4.78075464e-01  2.03280132e-01  4.40847297e-03  1.76832932e-02]\n",
      " [ 3.42723079e-02  4.91558896e-02  1.58455409e-01  2.54397565e-02\n",
      "  -6.25338849e-02 -1.50091291e-02  1.00000000e+00  1.54496486e-02\n",
      "  -6.84897180e-02 -7.83309809e-03  2.09802502e-01 -6.20937523e-02\n",
      "  -2.25418810e-02 -1.82345421e-01  1.09735298e-01  1.78484857e-01]\n",
      " [ 3.09459862e-02 -1.98787836e-03  4.41139362e-01  1.85594822e-02\n",
      "   1.08301490e-01  3.29314754e-02  1.54496486e-02  1.00000000e+00\n",
      "  -6.23776061e-02  6.45306769e-02 -9.24522868e-02 -8.50789233e-03\n",
      "  -1.04333998e-01  3.50527008e-02  1.08643355e-01  8.78559155e-02]\n",
      " [-1.59635102e-01 -2.21534591e-01 -1.55700570e-01  5.81939785e-02\n",
      "  -2.09624954e-01  2.38249571e-02 -6.84897180e-02 -6.23776061e-02\n",
      "   1.00000000e+00 -1.44451030e-01 -5.52950260e-02 -8.10421274e-02\n",
      "   3.89038455e-02  1.73872427e-01 -8.77321090e-02 -4.81158371e-01]\n",
      " [-1.09800849e-01  1.43925217e-03  1.23994725e-03  1.42737780e-01\n",
      "  -1.28338576e-02 -2.66840046e-02 -7.83309809e-03  6.45306769e-02\n",
      "  -1.44451030e-01  1.00000000e+00 -2.25300876e-02 -2.53039681e-01\n",
      "  -1.36125132e-02 -1.04765199e-01  6.01148536e-02 -1.51572862e-02]\n",
      " [ 1.63866377e-02  2.04708662e-02  1.68233668e-01 -1.51894397e-02\n",
      "   3.64606888e-02 -1.25661380e-01  2.09802502e-01 -9.24522868e-02\n",
      "  -5.52950260e-02 -2.25300876e-02  1.00000000e+00  9.27367505e-02\n",
      "  -1.98291751e-01 -5.34866938e-01 -5.38157151e-02  1.06344316e-02]\n",
      " [-2.54013540e-03  5.71654378e-03 -4.75864506e-03 -5.48903359e-02\n",
      "   3.26891196e-02  4.75272366e-02 -6.20937523e-02 -8.50789233e-03\n",
      "  -8.10421274e-02 -2.53039681e-01  9.27367505e-02  1.00000000e+00\n",
      "   4.11013935e-02  2.31523867e-03 -8.54806083e-02  1.71066692e-01]\n",
      " [-1.00838723e-02  6.55544474e-03 -1.12071163e-01 -2.19475084e-02\n",
      "  -4.91237880e-02  4.78075464e-01 -2.25418810e-02 -1.04333998e-01\n",
      "   3.89038455e-02 -1.36125132e-02 -1.98291751e-01  4.11013935e-02\n",
      "   1.00000000e+00  3.78910301e-01  9.70252342e-04 -2.62695935e-02]\n",
      " [-5.52887041e-02 -4.63618313e-02 -9.29674377e-02 -3.00955414e-02\n",
      "  -9.30913486e-02  2.03280132e-01 -1.82345421e-01  3.50527008e-02\n",
      "   1.73872427e-01 -1.04765199e-01 -5.34866938e-01  2.31523867e-03\n",
      "   3.78910301e-01  1.00000000e+00 -2.85313185e-03 -4.09108447e-02]\n",
      " [ 7.00147269e-01  4.67355284e-02  4.09347085e-01  7.25766177e-02\n",
      "  -1.26728036e-01  4.40847297e-03  1.09735298e-01  1.08643355e-01\n",
      "  -8.77321090e-02  6.01148536e-02 -5.38157151e-02 -8.54806083e-02\n",
      "   9.70252342e-04 -2.85313185e-03  1.00000000e+00  1.76676475e-01]\n",
      " [ 1.72933594e-01  1.89290500e-01  1.76028387e-01 -3.65409171e-02\n",
      "   1.68868098e-01  1.76832932e-02  1.78484857e-01  8.78559155e-02\n",
      "  -4.81158371e-01 -1.51572862e-02  1.06344316e-02  1.71066692e-01\n",
      "  -2.62695935e-02 -4.09108447e-02  1.76676475e-01  1.00000000e+00]]\n",
      "(16, 16)\n",
      "did that work?\n",
      "correlation stuff above\n",
      "100\n",
      "range(0, 100)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Running LIONESS for sample 1:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 1 to lioness_output using npy format:\n",
      "  Elapsed time: 0.13 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 2:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 2 to lioness_output using npy format:\n",
      "  Elapsed time: 0.13 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 3:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 3 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 4:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 4 to lioness_output using npy format:\n",
      "  Elapsed time: 0.52 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 5:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 5 to lioness_output using npy format:\n",
      "  Elapsed time: 0.21 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 6:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 6 to lioness_output using npy format:\n",
      "  Elapsed time: 0.13 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 7:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 7 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 8:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 8 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 9:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 9 to lioness_output using npy format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 10:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 10 to lioness_output using npy format:\n",
      "  Elapsed time: 0.13 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 11:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 11 to lioness_output using npy format:\n",
      "  Elapsed time: 0.18 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 12:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 12 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 13:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 13 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 14:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 14 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 15:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 15 to lioness_output using npy format:\n",
      "  Elapsed time: 0.10 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 16:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 16 to lioness_output using npy format:\n",
      "  Elapsed time: 0.13 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 17:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.01 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 17 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 18:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 18 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 19:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 19 to lioness_output using npy format:\n",
      "  Elapsed time: 0.10 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 20:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 20 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 21:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 21 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 22:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 22 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 23:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 23 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 24:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 24 to lioness_output using npy format:\n",
      "  Elapsed time: 0.12 sec.\n",
      "BOOOOOOOOM\n",
      "Running LIONESS for sample 25:\n",
      "Computing coexpression network:\n",
      "howdy one\n",
      "(16, 100)\n",
      "are these indices okay?\n",
      "(16, 99)\n",
      "(16, 16)\n",
      "  Elapsed time: 0.00 sec.\n",
      "Normalizing networks:\n",
      "  Elapsed time: 0.00 sec.\n",
      "Inferring LIONESS network:\n",
      "here?\n",
      "  Elapsed time: 0.00 sec.\n",
      "did we get here boo boo 2?\n",
      "Saving LIONESS network 25 to lioness_output using npy format:\n",
      "  Elapsed time: 0.11 sec.\n",
      "BOOOOOOOOM\n",
      "25\n",
      "(16, 16)\n",
      "finished?\n",
      "25\n",
      "(16, 16)\n",
      "hooowra\n",
      "did this actually save?\n",
      "let's see if we got this far\n",
      "Fitting Population Model...\n",
      "Epoch 1/10\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1, 1, 16), dtype=float32)\n",
      "Tensor(\"lambda/MatMul:0\", shape=(1, 1, 16), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"lambda/strided_slice:0\", shape=(), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1, 1, 16), dtype=float32)\n",
      "Tensor(\"lambda/MatMul:0\", shape=(1, 1, 16), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"lambda/strided_slice:0\", shape=(), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 347.8862\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 0s 924us/step - loss: 250.8855\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 0s 912us/step - loss: 195.2302\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 0s 919us/step - loss: 160.1277\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 0s 934us/step - loss: 136.7603\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 0s 933us/step - loss: 120.5710\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 0s 934us/step - loss: 109.2260\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 0s 948us/step - loss: 100.9282\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 0s 919us/step - loss: 94.7126\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 0s 858us/step - loss: 90.0721\n",
      "Finished Fitting Population Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stsou/miniconda2/envs/tarrLab/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDDDDIIIIIDDDD WE GET THROUGH THE F1 SCORES?\n",
      "100\t4\t8\t1.000\t2\t1\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 209.4254\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 147.2389\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 123.9518\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 112.2851\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 105.2448\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 991us/step - loss: 100.5700\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 998us/step - loss: 97.1314\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 946us/step - loss: 94.3955\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 938us/step - loss: 92.1140\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 90.1024\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 955us/step - loss: 88.3592\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 943us/step - loss: 86.7524\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 944us/step - loss: 85.3034\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 943us/step - loss: 83.9971\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 82.8124\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 962us/step - loss: 81.7538\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 970us/step - loss: 80.8100\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 937us/step - loss: 79.9765\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 930us/step - loss: 79.2521\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 945us/step - loss: 78.6969\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 943us/step - loss: 78.1549\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 946us/step - loss: 77.7221\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 968us/step - loss: 77.3506\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 940us/step - loss: 76.9533\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 959us/step - loss: 76.6369\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 951us/step - loss: 76.3088\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 949us/step - loss: 76.0527\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 956us/step - loss: 75.8753\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 931us/step - loss: 75.6510\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 923us/step - loss: 75.4532\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 928us/step - loss: 75.2569\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 940us/step - loss: 75.1128\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 944us/step - loss: 74.9127\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.7306\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 961us/step - loss: 74.6078\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.4759\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 952us/step - loss: 74.3425\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 978us/step - loss: 74.2452\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 944us/step - loss: 74.1324\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.9650\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.9119\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7918\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7016\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7188\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.5185\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.4982\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.4097\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.2530\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.1488\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.2241\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 319.5675\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 236.6224\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 187.0568\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 154.7172\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 132.7424\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 117.2985\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 106.3939\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 98.4703\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.6818\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.2865\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.9584\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.3040\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.2077\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.5218\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.1161\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.9416\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.8843\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.0759\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.2344\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.5801\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1779\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.4618\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0612\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7111\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.3161\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.0693\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.7490\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4385\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1905\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1136\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8768\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7535\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.5761\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4093\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3231\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1564\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0541\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0306\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9574\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7871\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7575\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7172\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5629\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5631\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5726\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5089\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4254\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4286\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3772\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3031\n",
      "100\t4\t8\t1.000\t2\t2\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 116.0913\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 97.4388\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 89.1231\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.8223\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.3205\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.6873\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.3966\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.3145\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.5540\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.7713\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.0722\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.4847\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.9958\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.5066\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.0726\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7199\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.3886\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.0591\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.7265\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4376\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.2438\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.9567\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.8080\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.5813\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.3667\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2582\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0497\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.8998\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 70.7779\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 970us/step - loss: 70.6071\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 971us/step - loss: 70.4698\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 984us/step - loss: 70.3916\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 959us/step - loss: 70.2702\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 70.1429\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 996us/step - loss: 70.1059\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 970us/step - loss: 69.9479\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 991us/step - loss: 69.8130\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 989us/step - loss: 69.8047\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 970us/step - loss: 69.6515\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 955us/step - loss: 69.5707\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 946us/step - loss: 69.5093\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 954us/step - loss: 69.4681\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 69.3205\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 979us/step - loss: 69.2598\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 967us/step - loss: 69.2085\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 980us/step - loss: 69.1486\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 955us/step - loss: 69.0922\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 971us/step - loss: 69.0680\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 961us/step - loss: 69.0716\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 979us/step - loss: 68.8956\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 137.6913\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 115.7261\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 103.0290\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 94.9562\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 89.1813\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 84.8325\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 81.6820\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 78.9184\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 76.8900\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 75.1931\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 73.8593\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 72.6819\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.8686\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.1756\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.6846\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.1381\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.8095\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.4555\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.1544\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.9149\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.7178\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.5336\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.4095\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.3425\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.0956\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.0836\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9370\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7636\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7297\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6268\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5467\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5480\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5434\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4072\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3652\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3337\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2682\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1993\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1360\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2953\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0740\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0477\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0564\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9833\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9758\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9417\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9412\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9297\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8622\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7842\n",
      "100\t4\t8\t1.000\t2\t3\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 97.9749\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 91.8139\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 974us/step - loss: 88.0592\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.1352\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 990us/step - loss: 82.8791\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 993us/step - loss: 80.8928\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.3323\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1000us/step - loss: 78.0869\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 970us/step - loss: 76.9743\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 954us/step - loss: 76.0591\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 958us/step - loss: 75.1726\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 979us/step - loss: 74.4622\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 964us/step - loss: 73.8500\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 954us/step - loss: 73.2201\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 969us/step - loss: 72.6456\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 959us/step - loss: 72.1493\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 956us/step - loss: 71.6384\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 960us/step - loss: 71.2861\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 948us/step - loss: 70.8193\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 958us/step - loss: 70.4604\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 956us/step - loss: 70.1100\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 929us/step - loss: 69.8325\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 936us/step - loss: 69.5247\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 69.3294\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 958us/step - loss: 69.0987\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 955us/step - loss: 68.8971\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 969us/step - loss: 68.6638\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 964us/step - loss: 68.5655\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 973us/step - loss: 68.3680\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 958us/step - loss: 68.1978\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 966us/step - loss: 68.0706\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 962us/step - loss: 68.0216\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 978us/step - loss: 67.7859\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 67.6770\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 67.4900\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 955us/step - loss: 67.4352\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 945us/step - loss: 67.2790\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 67.2076\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 956us/step - loss: 67.1736\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 953us/step - loss: 66.9896\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 959us/step - loss: 66.9334\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 66.8873\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 936us/step - loss: 66.7775\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 936us/step - loss: 66.7169\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 941us/step - loss: 66.6064\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 950us/step - loss: 66.5569\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4515\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3812\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 964us/step - loss: 66.2906\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 947us/step - loss: 66.2657\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 111.0032\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 97.2958\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 89.9333\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 85.1478\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 81.3770\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 78.6272\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 76.4368\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 74.7991\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 73.3945\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 72.2614\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.4195\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.7537\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.1931\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.8061\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.5479\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.1845\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.9287\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.7035\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.5485\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.4176\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.3281\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.2479\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.1161\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.0133\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.9552\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.9504\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.8105\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.7625\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.6345\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.6276\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.6384\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.5999\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.5511\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4714\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4870\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4530\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.3664\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.3672\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.3029\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2885\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2816\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2482\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2545\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2841\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2059\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.1942\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.1550\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2388\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.1666\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.1189\n",
      "100\t4\t8\t1.000\t2\t4\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 98.7560\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.4895\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.4153\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.2448\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.5686\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.4429\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.6623\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.2584\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.0453\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.0858\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.2604\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.6245\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.9946\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4432\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 954us/step - loss: 71.8895\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 964us/step - loss: 71.4768\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 973us/step - loss: 71.0830\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 972us/step - loss: 70.7921\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 973us/step - loss: 70.3522\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 976us/step - loss: 70.1088\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 987us/step - loss: 69.8211\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 971us/step - loss: 69.5015\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 972us/step - loss: 69.3321\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 986us/step - loss: 69.1268\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 983us/step - loss: 68.9477\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 978us/step - loss: 68.7362\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 973us/step - loss: 68.6147\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 971us/step - loss: 68.4686\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 963us/step - loss: 68.3197\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 951us/step - loss: 68.2221\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 951us/step - loss: 68.0432\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 950us/step - loss: 67.9841\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 981us/step - loss: 67.8178\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 988us/step - loss: 67.7449\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 967us/step - loss: 67.6268\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6255\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 986us/step - loss: 67.5454\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4034\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 991us/step - loss: 67.3438\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2903\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 973us/step - loss: 67.1142\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 66.9860\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 978us/step - loss: 66.9449\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 977us/step - loss: 66.9251\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 946us/step - loss: 66.7767\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 951us/step - loss: 66.7151\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 928us/step - loss: 66.6955\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6117\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5272\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 949us/step - loss: 66.4620\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 102.8646\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 91.1771\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 85.0105\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 81.0578\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 78.2435\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 76.0167\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 74.1948\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 72.8591\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.8150\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.9136\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.2509\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.6768\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.2541\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.9306\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.7384\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.4367\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.2418\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.1085\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.9558\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.7780\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.6471\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4714\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4292\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.3154\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2265\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.1311\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.0500\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.9439\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.8827\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 66.7802\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.7061\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.5610\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.5084\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.3830\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.2964\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.1969\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.0917\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.0326\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.8397\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.7835\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.6208\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.5490\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.4412\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.3086\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.1885\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.0287\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.9334\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.8010\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.5795\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.4876\n",
      "100\t4\t8\t1.000\t2\t5\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.5503\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.0552\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 995us/step - loss: 88.6488\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 997us/step - loss: 85.4913\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.8182\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.7958\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 989us/step - loss: 79.0336\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 999us/step - loss: 77.6069\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.3580\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 944us/step - loss: 75.2732\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 932us/step - loss: 74.3513\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 954us/step - loss: 73.4726\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 940us/step - loss: 72.6871\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 957us/step - loss: 72.1194\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 960us/step - loss: 71.5146\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 949us/step - loss: 70.9705\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 949us/step - loss: 70.4677\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 932us/step - loss: 70.1987\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 930us/step - loss: 69.9336\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 952us/step - loss: 69.5003\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 950us/step - loss: 69.2420\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 947us/step - loss: 69.0534\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 949us/step - loss: 68.7890\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 965us/step - loss: 68.6219\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 939us/step - loss: 68.4525\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 952us/step - loss: 68.3019\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 966us/step - loss: 68.1010\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9892\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7770\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7027\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6452\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4413\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3610\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2536\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1147\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0795\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9999\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8891\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7833\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6898\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6403\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5366\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4368\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3797\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3614\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1945\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1198\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0873\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9665\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9245\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 102.5168\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 92.1468\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 86.0656\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 81.8746\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 78.6877\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 76.2279\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 74.3611\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 72.9086\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 71.8261\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 70.9055\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 70.2600\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.7337\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.3882\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.0337\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.6592\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.4182\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.2333\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.9899\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8822\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.7485\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.7381\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.5223\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3166\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.2656\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1517\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.0037\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.9565\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.8384\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.7689\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.5665\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.4918\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.3705\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.3012\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.1223\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.0232\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.9706\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.7127\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.5781\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.4724\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.2791\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.1482\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.9877\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.7827\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.6357\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.4736\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.2580\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.1473\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 63.9089\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 63.7059\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 63.6149\n",
      "100\t4\t8\t1.000\t2\t6\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.5288\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 91.9927\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.7538\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.4185: 0s - loss: 83.72\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.5711\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.1917\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.4738\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.1247\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.0967\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.1624\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.3304\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.6924\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.0516\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4827\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1023\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.6362\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2646\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.8195\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.4997\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.1809\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.9102\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.6960\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4895\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.2255\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1076\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8847\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6286\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.5211\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3685\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1803\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0281\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9642\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7525\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7185\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5749\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4878\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3707\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3358\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1602\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1342\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0905\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9388\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 992us/step - loss: 66.8561\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8171\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7118\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6691\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5305\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4903\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3718\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3585\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 97.2423\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 88.5656\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 83.3518\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 79.4903\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 76.6830\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 74.4141\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 72.8855\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.6108\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.5763\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.8587\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 69.3187\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.8998\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.5193\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 68.1240\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.9560\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.7230\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4964\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.4159\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.2553\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 67.0696\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 66.9204\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.7704\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.5372\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.4061\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.2943\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.0626\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.0282\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.7935\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.6324\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.4845\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.1935\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.1086\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.8759\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.6751\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.5313\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.2785\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.1262\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.9606\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.7400\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.5522\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.2879\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.0564\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.8803\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.6959\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.5429\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.3607\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.0972\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.9572\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.7982\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.6150\n",
      "100\t4\t8\t1.000\t2\t7\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.0745\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 91.5839\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 87.7881\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.4589\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.8251\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.9188\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.3774\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.2152\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.2188\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.2331\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.4014\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7124\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.1546\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.6027\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1260\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.7884\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.3727\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0645\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7600\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.4500\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.1885\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.8921\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.7108\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4877\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.3403\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1006\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.9541\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7910\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6501\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4675\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3985\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.2615\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0758\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9835\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9011\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7766\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7801\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5866\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5332\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4370\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3190\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3058\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2400\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1572\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1095\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1137\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0120\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9258\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8892\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8465\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 97.6529\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 88.0202\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 82.7682\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 79.1425\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 76.4690\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 74.4040\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 72.8807\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 71.5615\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 70.7688\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.9715\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.4507\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.0304\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.7558\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.4480\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.3725\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.1429\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8947\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8391\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8253\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.7428\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.6528\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.5038\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3644\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3937\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.2964\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1721\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1527\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1069\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.0210\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.9729\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.8454\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.8085\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.7493\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.6934\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.4710\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.4246\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.3462\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.2246\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 66.0933\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.9845\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.9569\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.7851\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.6612\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.5058\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.4276\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.2236\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 65.0138\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.8704\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.7242\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 64.6163\n",
      "100\t4\t8\t1.000\t2\t8\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.0923\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 91.3351\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 87.5760\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.1397\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.5276\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.7172\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.3463\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.1828\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.0302\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.0121\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.2083\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.3910\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.6445\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1044\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.6412\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2171\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7105\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.3988\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.0531\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 999us/step - loss: 69.7641\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4806\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.2396\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.0659\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8352\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 992us/step - loss: 68.6209\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4604\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 997us/step - loss: 68.3320\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1170\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 997us/step - loss: 67.9759\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.8810\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7347\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5820\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4535\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3293\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2863\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0914\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0523\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8757\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8241\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6990\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6308\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4922\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3929\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3112\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2335\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1514\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1072\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9233\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 993us/step - loss: 65.9055\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 992us/step - loss: 65.7838\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 97.6603\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 87.8465\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 82.5362\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 78.9974\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 76.2141\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 74.1473\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 72.4592\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 71.2270\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 70.2583\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.6858\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.1552\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.7121\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 3ms/step - loss: 68.4074\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.1152\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8916\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.7417\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.4969\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.4702\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.2343\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1108\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.9559\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.7810\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.6347\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.4608\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.3439\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.1338\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.9502\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.7912\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.5471\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.5272\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.2188\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.9761\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.8067\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.5696\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.3542\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.0875\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.9326\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.6620\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.3821\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.2266\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.9496\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.7233\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.4219\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.2231\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.0394\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.7567\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.5625\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.4504\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.2253\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.0076\n",
      "100\t4\t8\t1.000\t2\t9\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 94.9108\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 90.5669\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 86.7674\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 83.5977\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.5796\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.2754\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.0328\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.9409\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.9115\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.8568\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.9748\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.1654\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.3492\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.6026\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 998us/step - loss: 71.8981\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2903\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7339\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.2965\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.8474\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.3888\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.0503\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6967\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4389\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.2244\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9817\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6513\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5203\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3155\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1558\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9889\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8179\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7095\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5148\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3520\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2395\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0918\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0018\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8435\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7738\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6553\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5169\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4139\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2798\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1567\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0391\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9201\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.8281\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.7395\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.6388\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.5375\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 98.1390\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 88.4238\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 82.9146\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 79.3847\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 76.5583\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 74.5008\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 72.8214\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 71.5911\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 70.6805\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.9348\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.3554\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.9787\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.6585\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.3736\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.1837\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.9679\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8826\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.7428\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.5825\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.4599\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3467\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1946\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1017\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.0258\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.7949\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.6771\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.5597\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.5014\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.2283\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.1110\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.9242\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.6861\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.5216\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.4458\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.2543\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.0453\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.7700\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.5465\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.3409\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.1754\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.9649\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.7305\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.3847\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.2600\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.0459\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.8504\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.6185\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.4600\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.1402\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.9560\n",
      "100\t4\t8\t1.000\t2\t10\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.9964\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 91.8332\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.0938\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.6158\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.8699\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.9868\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.6608\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.5553\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.4511\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.4034\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.5460\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.6383\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.9711\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.2491\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.5606\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0488\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.5327\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.0894\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.7170\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.3753\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.0957\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6716\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4569\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1938\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9744\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7155\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5183\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3059\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1373\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9692\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8126\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6279\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3931\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2449\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1340\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9134\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8107\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6761\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5329\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3459\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2659\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1816\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0310\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.8884\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.8272\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.6845\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.5856\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.5229\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.3822\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.2894\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 94.7551\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 86.2375\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 81.5975\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 78.2323\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 4ms/step - loss: 75.7859\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 73.7563\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 72.3234\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 71.2667\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 70.4282\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 69.7598\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 69.2605\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.8243\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.5006\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.3187\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.1007\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.8651\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.6523\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.5007\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3425\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.1899\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.0176\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.9554\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.7532\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.6161\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.5202\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.3059\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 66.1489\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.9967\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.8613\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.6332\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.5441\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.3418\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 65.1817\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.9419\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.7735\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.5434\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.4076\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.1006\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.9166\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.6515\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.4622\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.2800\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.0373\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.8437\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.6729\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.4393\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.2014\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.1208\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.8768\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.7226\n",
      "100\t4\t8\t1.000\t2\t11\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.7187\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.0857\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.5183\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.0011\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.2631\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.3766\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.0754\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.8995\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.8799\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.7677\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.8084\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.7568\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.0006\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1925\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.5036\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.8770\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.3925\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 999us/step - loss: 69.9696\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.5683\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1599\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8562\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4859\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3611\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 986us/step - loss: 68.0223\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7092\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5781\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3235\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 996us/step - loss: 67.0980\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 982us/step - loss: 66.9434\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8139\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 979us/step - loss: 66.6001\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3679\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 992us/step - loss: 66.2750\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0146\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8406\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7933\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5665\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 987us/step - loss: 65.4100\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 984us/step - loss: 65.2561\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 997us/step - loss: 65.1290\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 997us/step - loss: 64.9542\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 988us/step - loss: 64.8354\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 993us/step - loss: 64.6589\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 991us/step - loss: 64.5932\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 988us/step - loss: 64.4416\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 985us/step - loss: 64.3434\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.1473\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.0850\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 999us/step - loss: 63.9190\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 999us/step - loss: 63.8296\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step - loss: 92.3897\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 85.0139\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 80.7821\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 77.6455\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 75.3120\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 73.4833\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 72.0352\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 71.0438\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 70.2313\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 69.6077\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.0654\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.7056\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.4247\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.1700\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.8716\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.7432\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.5533\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.4012\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.1006\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.0242\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.9253\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.6966\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.4726\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.3066\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.2182\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.0626\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.7882\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.6899\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.4285\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.2228\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.0509\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.7643\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.5907\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.2960\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 64.0776\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.8398\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.6467\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.3551\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 63.1080\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.9367\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.6731\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.4214\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.1706\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 62.0352\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.8203\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.6202\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.5669\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.2950\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 61.1558\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 60.9695\n",
      "100\t4\t8\t1.000\t2\t12\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.9026\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.3205\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.5532\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.0061\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.2708\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.4510\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.0231\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.0162\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.9136\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.9503\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.0698\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.2369\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.4420\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.8286\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.2609\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.7377\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2030\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.8234\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.4099\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.0159\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.6652\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.3640\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.0849\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8295\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6359\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3725\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.2480\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0422\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.8314\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7131\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5413\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4760\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3550\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1714\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0749\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8615\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8173\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7094\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5255\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4811\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3219\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2243\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1136\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0344\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8848\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7756\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5766\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5646\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4131\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2685\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 94.0699\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 85.9996\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 81.4451\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 78.2221\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 75.6695\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 73.7593\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 72.1906\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 71.1294\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 70.2939\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.6930\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.0705\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.7102\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.4220\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.1515\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.9365\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.7916\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.5816\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.4133\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.2696\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.1434\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.9520\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.8818\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.6396\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.5166\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.3464\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.1252\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.0362\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.8554\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.5523\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.3731\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.1509\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.9184\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.6492\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.3625\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.1129\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.8029\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.5928\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.3439\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.9743\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.7843\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.5010\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.2132\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.9822\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.8232\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.5141\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.3951\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.0551\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.9107\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.7003\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.5654\n",
      "100\t4\t8\t1.000\t2\t13\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.0318\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.4072\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.5085\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.6487\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.8424\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.0929\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.9180\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.0097\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.0113\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.1499\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.2422\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.4507\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.6103\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.8910\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.2046\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.5823\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.1784\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.5760\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.1808\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.8050\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4595\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1663\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8321\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6526\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3829\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1525\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9397\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7603\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6559\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4566\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2873\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1630\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9542\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8294\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7615\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5797\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4358\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3441\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2021\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0428\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9892\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8281\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7454\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5702\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4791\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3039\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2501\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1440\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9460\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9221\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 95.3306\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 86.8553\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 81.9817\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 78.5715\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 75.8797\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 73.9052\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 72.2844\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 71.1675\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 70.2716\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 69.4950\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 69.0676\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.5091\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 68.1702\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.8853\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.5705\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.4184\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.2198\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.0050\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.7869\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.5930\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.4110\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.0983\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.0007\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.8195\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.6456\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.3747\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.0786\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.8956\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.6893\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.3963\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.0943\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.8660\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.6534\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.3498\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 63.1488\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.9366\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.6469\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.5289\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.1944\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 62.0411\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.7486\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.6010\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.3583\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.2359\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.0245\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.9193\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.6751\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.5080\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.3745\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.2875\n",
      "100\t4\t8\t1.000\t2\t14\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.7458\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.1182\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.2829\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.6600\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.0628\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.3285\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.2290\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.1517\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.1165\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.1418\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.1549\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.3239\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.5392\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.7354\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.1447\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.6496\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.1447\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7261\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.3028\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.9506\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.6075\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.3413\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1434\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8657\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6575\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4547\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3213\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1064\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9613\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7762\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6236\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5693: 0s - loss: 67.51\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3940\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2514\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1014\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9487\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8983\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7278\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6411\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4813\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3335\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2053\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1503\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0153\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8778\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7827\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6017\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5144\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3895\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2988\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 92.5048\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 85.2914\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 81.0938\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 77.9186\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 75.4805\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 73.6734\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 72.1412\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 71.0223\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 70.2784\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.6714\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 69.0154\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.7036\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.3078\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 68.1173\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.8640\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.6976\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.5613\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 67.3603\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.1876\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.0905\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.9331\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.7476\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.5522\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.3530\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.2368\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.1125\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.8388\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.6635\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.4651\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.2232\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.0339\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.7456\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 64.5803\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.3477\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.0937\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.8500\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.5702\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.4026\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.1085\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.8960\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.6256\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.3658\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.1682\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.9348\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.7233\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.5310\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.3526\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 61.1703\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.0011\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 60.8199\n",
      "100\t4\t8\t1.000\t2\t15\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.5768\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.1790\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.4009\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.8299\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.1924\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.4819\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.1941\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.0897\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.8728\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.9394\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.9092\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.0122\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.2697\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4051\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.7250\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.1632\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.5786\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.9966\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.5834\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.0952\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7205\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4838\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1858\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.8804\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6437\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4380\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1923\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0159\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8799\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6537\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5184\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3712\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2588\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0900\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9320\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7831\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6669\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5400\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3292\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2474\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1101\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0301\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9034\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.8526\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.7335\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.5876\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.4494\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.2973\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.2434\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.1296\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 93.7217\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 85.6259\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 80.9864\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 77.7925\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 75.3401\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 73.4017\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 71.9304\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 70.8415\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 70.0693\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.5102\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.0141\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.7193\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.3759\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.1881\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.0322\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.7730\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.6555\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.5282\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.3630\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.2330\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.1710\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 67.0557\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.9099\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.7993\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.5834\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.4780\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.2927\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 66.1428\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.9516\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.8481\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 65.5122\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.3164\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.0620\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.9293\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.5896\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.3373\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.0458\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.7822\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.5421\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.1876\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.9639\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.6750\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.4309\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.1821\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.9323\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.7184\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.4885\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.2842\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.0855\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.8780\n",
      "100\t4\t8\t1.000\t2\t16\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 95.9162\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.4678\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.3821\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.5286\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.9901\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.4177\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.3693\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.5041\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.4954\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.5763\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.6179\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.8009\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.9184\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.2413\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4991\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.9261\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.3020\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7903\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.3077\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.8876\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.5646\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.1852\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.8655\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7048\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3478\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.0882\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9127\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6927\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4656\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3456\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1046\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8598\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7553\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6427\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4515\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3046\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1648\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0193\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8066\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6836\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5561\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4137\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2937\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1688\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0357\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9318\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.7802\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.6162\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.5258\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.4062\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 92.7756\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 85.3296\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 80.9724\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 77.8123\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 75.3699\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 73.5644\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 72.1308\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 71.0618\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 70.1589\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 69.5661\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 69.1540\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.7124\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.4209\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.2434\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 68.0582\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.8594\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.7229\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.5880\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.4201\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.3526\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.2086\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.0070\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.9437\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.8465\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.6321\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.5713\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.3661\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 66.2294\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 66.0342\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 65.8726\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 65.7205\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 65.5337\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 65.3577\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 65.0525\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.9109\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.6666\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.4651\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.2139\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.9566\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.6798\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.4740\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.2238\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.0541\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.7171\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.4950\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.2752\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.9830\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.8346\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.6920\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.3958\n",
      "100\t4\t8\t1.000\t2\t17\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.1546\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.6914\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.6953\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.4858\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.8662\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.3319\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.2812\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.4134\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.4824\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.5249\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.5690\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.7070\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.9112\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.1585\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4460\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.8337\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.2251\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.7126\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.2422\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.8606\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.5417\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.2381\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.9288\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6851\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.4288\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.2728\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9957\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.7691\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6767\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.5119\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3476\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1591\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0067\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8677\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7265\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6074\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4832\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3901\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.2199\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.0604\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9646\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7586\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6702\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5075\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3644\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2573\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1604\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0648\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.9258\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 64.7643\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 93.9682\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 85.9188\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 81.2048\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 77.9965\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 75.3761\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 73.4286\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 71.9654\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 70.9416\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 70.0352\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 69.4094\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.9511\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.5804\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.3482\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.1459\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.9114\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.7153\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.6628\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.4387\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.2520\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 67.1152\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.9618\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.8379\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.6730\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.4741\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.2745\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.1333\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.0004\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.8186\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.5270\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.2685\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.0307\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.8318\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.5706\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.3007\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 64.0307\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.8346\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.5248\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.2631\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 63.0419\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.7477\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.5191\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.3666\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.0492\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.8413\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.7045\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.4967\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.2662\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 61.1245\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 60.8911\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 60.7309\n",
      "100\t4\t8\t1.000\t2\t18\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.0932\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.6612\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.4584\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 84.4287\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 81.8763\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.3350\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.4476\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.5793\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.6556\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.6914\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.8160\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.9727\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.1338\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.4172\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.6901\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.0963\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.5666\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0401\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.6061\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.1730\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.9152\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.4454\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.2322\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.9311\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7446\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.5085\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3169\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1768\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9342\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.8328\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6088\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4790\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3256\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.2310\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0339\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.8745\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6936\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5555\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4542\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3352\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1793\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9939\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9378\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7474\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.6412\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5424\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4602\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3158\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1847\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.0870\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 92.3292\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 84.9224\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 80.7321\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 77.5403\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 75.2536\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 73.2727\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 71.8822\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 70.7229\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 69.9680\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 69.2947\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 68.8434\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 68.4652\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 68.2274\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 68.0459\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 67.8056\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 67.6073\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 67.3824\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 67.2300\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.0330\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 66.8754\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.7173\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.5705\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.3961\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 66.1897\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.9356\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.7075\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.6271\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 65.3251\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 65.0542\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.8563\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.5522\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.3239\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 64.0646\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 63.7263\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 63.4315\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 7ms/step - loss: 63.1869\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.9637\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.6101\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 62.4167\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 62.1170\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.8196\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.6214\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.4134\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.2548\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 61.0477\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.8383\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.6374\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.4578\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.3448\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 60.1548\n",
      "100\t4\t8\t1.000\t2\t19\tEpoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 96.2227\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 92.8731\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 88.9520\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 85.0192\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 82.3539\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 80.8653\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 79.7494\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 78.7496\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 77.8119\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 76.8559\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 75.9192\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.9456\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 74.0494\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 73.1871\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 72.4193\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.7121\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 71.0749\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.5386\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 70.0054\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.7115\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 69.2917\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.9667\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.7845\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.6328\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.3674\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 68.1883\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.9851\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.8389\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6931\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.6123\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.4111\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.3321\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.1912\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 67.0559\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.9452\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.7579\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.6221\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.5069\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.4344\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.3099\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1837\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 66.1191\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.9903\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.8506\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.7189\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.5874\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.4601\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.3690\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.2602\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 65.1582\n",
      "Epoch 1/50\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 93.5202\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 85.6792\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 81.0823\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 77.8597\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 75.3051\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 73.4678\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 72.0507\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 70.9461\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 70.0634\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 69.4403\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.9876\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.6798\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.3356\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 68.1201\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.8835\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.6797\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.5534\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.4297\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 67.2348\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 67.0374\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 66.8542\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 66.6487\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 66.4782\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 66.2759\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 65.9965\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 65.7868\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 65.5336\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 65.3037\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 64.9830\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 64.6412\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 64.3783\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 63.9791\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 63.7006\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 63.3040\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 63.0659\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 62.7125\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 62.4733\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 62.1732\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 61.9122\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 61.6289\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 61.3506\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 61.1301\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.9532\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.7492\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.5274\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.3053\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.1561\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 60.0028\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 59.8938\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 59.7534\n",
      " ALLLL THROUGH   \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9ffc3ef28595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" ALLLL THROUGH   \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#####   NON CONVEX CASE    ####### \n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/c_notears_paramsweepNonConvNaive.csv\", 'w') as out_file:\n",
    "    print(\"n\\tn_edges\\tn_c\\tcontext_snr\\tk_true\\tk\", end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"base_{:.3f}\".format(x) for x in threshs]), end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lioness_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"c_notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lr_c_notears_{:.3f}\".format(x) for x in threshs]), file=out_file)\n",
    "    \n",
    "    #for arch in range(2, 20):  #number of archetypes\n",
    "    data_params = {\n",
    "\"n\": 100,    # number of DAGs\n",
    "\"n_i\": 1,     # number of samples per DAG\n",
    "\"d\" : 16,       # number of vertices in each DAG\n",
    "\"n_edges\": 4,     # expected number of edges in each DAG\n",
    "\"n_c\": 8,    # number of contextual features\n",
    "\"use_archetypes\": True,\n",
    "\"ensure_convex\" : False, # should the archetype be generated such that they form a convex set of DAGs?\n",
    "\"k_true\" : 2,       # number of true archetypes\n",
    "\"graph_type\": \"ER\",\n",
    "'sem_type' : 'gauss',\n",
    "'context_snr' : 1.0, # signal-to-noise ratio of the contextual data\n",
    "\"n_mix\": 2\n",
    "}\n",
    "\n",
    "##### This is where the blocked comments began. \n",
    "##### THIS IS WHERE I BEGIN MASSIVE INDENT  ##################\n",
    "\n",
    "    W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "\n",
    "    ####### THIS IS ALL OF THE LIONESS STUFF.  #######\n",
    "    ###### Make sure that the squeeze and split is consistent across models  ########\n",
    "\n",
    "    ####### I am moving all of this squeezing and unsqueezing and Dataframing South Of the Split  #######\n",
    "\n",
    "\n",
    "\n",
    "    C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "\n",
    "    ##### # Start Copy From Above   ######\n",
    "    X = np.squeeze(X)\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    #print(X)\n",
    "\n",
    "    C = pd.DataFrame(C)\n",
    "    ####### # End Copy From Above\n",
    "    print(\"this should all be the same as before\")\n",
    "    #assert False\n",
    "\n",
    "\n",
    "    C_test =pd.DataFrame(C_test)   # I think this is where the hitch was \n",
    "    index = C_test.index\n",
    "    a_list = list(index)\n",
    "    print(a_list)\n",
    "\n",
    "\n",
    "    ##### this is all from test_lioness   ########\n",
    "    ppi            ='puma/ToyData/ToyPPIData.txt'\n",
    "    motif          ='puma/ToyData/ToyMotifData.txt'\n",
    "    expression_data='puma/ToyData/ToyExpressionData.txt'\n",
    "    lioness_file   ='Travis'\n",
    "    rm_missing     =False\n",
    "    output_file    ='panda.npy'\n",
    "    gt_file        ='panda/test_panda.txt'\n",
    "    #panda_obj      =Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "    #                  keep_expression_matrix=bool(lioness_file), modeProcess='legacy', save_memory=False)\n",
    "    # Set parameters\n",
    "\n",
    "\n",
    "    #2. Testing Lioness with motif set to None to compute Lioness on coexpression networks\n",
    "    motif          = None\n",
    "    \n",
    "    # Make sure to keep epxression matrix for next step\n",
    "    panda_obj      = Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "                      keep_expression_matrix=True, modeProcess='legacy')\n",
    "    lioness_obj    = Lioness(panda_obj, data_params, X, a_list, start=1, end=1)\n",
    "   \n",
    "    lioness_obj.save_lioness_results(lioness_file)\n",
    "\n",
    "    res  = np.load('lioness_output/lioness.1.npy')\n",
    "    gt   = np.load('lioness/lionessCoexpression.1.npy')\n",
    "    W_OGLioness = pickle.load(open('lionessParams.pkl', 'rb'))\n",
    "\n",
    "    W_OGLioness = np.array(W_OGLioness)\n",
    "    \n",
    "    ##### This is where the block comments ended\n",
    "\n",
    "\n",
    "\n",
    "    #W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "    #C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "\n",
    "    notears = NOTEARS({'l1': 1e-3, 'alpha': 1e2, 'rho':1e1, 'gamma':1e1},\n",
    "                     (data_params[\"n_c\"], 1),\n",
    "                     (data_params[\"d\"], data_params[\"d\"]))\n",
    "    print(\"Fitting Population Model...\")\n",
    "    notears.fit(C_train, X_train, epochs=10, batch_size=1)\n",
    "    print(\"Finished Fitting Population Model.\")\n",
    "    pop_model = notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze()\n",
    "\n",
    "\n",
    "    def not_i(ar, i):\n",
    "        if i == 0:\n",
    "            return ar[1:]\n",
    "        if i == len(ar) - 1:\n",
    "            return ar[:-1]\n",
    "        return np.vstack((ar[:i], ar[i+1:]))\n",
    "    def lioness():\n",
    "        results = []\n",
    "        for i in range(data_params[\"n\"]):\n",
    "            print(\"{} / {}\".format(i, data_params['n']), end='\\r')\n",
    "            notears.model.set_weights([pop_model]) # initialize at pop model\n",
    "            notears.fit(not_i(C_train, i), not_i(X_train, i), epochs=3, batch_size=1, verbose=0)\n",
    "            results.append((data_params[\"n\"]-1)*(\n",
    "                notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze() - pop_model))\n",
    "        return results\n",
    "\n",
    "    f1s_lioness   = get_f1s(W_test, W_OGLioness, threshs)\n",
    "    f1s_baseline = get_f1s(W_test, np.ones_like(W_test), threshs)\n",
    "    C_test = C_test.to_numpy() \n",
    "    f1s_notears  = get_f1s(W_test, [notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test], threshs)\n",
    "\n",
    " \n",
    "\n",
    "    rank = 5\n",
    "    for k in range(1, 20):\n",
    "        print(\"k={}\".format(k), end='\\r')\n",
    "        model_params = {\n",
    "            \"k\": k,     # Learned archetype dictionary size\n",
    "            \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "            \"encoder_output_shape\": (k,),\n",
    "            \"dict_shape\": (k, data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "            \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "            \"learning_rate\": 1e-3\n",
    "        }\n",
    "        print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                     data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                      model_params[\"k\"]), end='\\t')\n",
    "\n",
    "        lr_model_params = {\n",
    "            \"k\": k,     # Learned archetype dictionary size\n",
    "            \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "            \"encoder_output_shape\": (k,),\n",
    "            \"dict_shape\": (k, data_params[\"d\"], rank),\n",
    "            \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "            \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "            \"learning_rate\": 1e-3\n",
    "        }\n",
    "        lr_c_notears = LRContextualNOTEARS(lr_model_params[\"encoder_input_shape\"],\n",
    "                                      lr_model_params[\"encoder_output_shape\"],\n",
    "                                      lr_model_params[\"dict_shape\"],\n",
    "                                     lr_model_params[\"sample_specific_loss_params\"],\n",
    "                                     lr_model_params[\"archetype_loss_params\"],\n",
    "                                     lr_model_params[\"learning_rate\"])\n",
    "        lr_c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "        c_notears = ContextualNOTEARS(model_params[\"encoder_input_shape\"],\n",
    "                                      model_params[\"encoder_output_shape\"],\n",
    "                                      model_params[\"dict_shape\"],\n",
    "                                     model_params[\"sample_specific_loss_params\"],\n",
    "                                     model_params[\"archetype_loss_params\"],\n",
    "                                     model_params[\"learning_rate\"])\n",
    "        c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "        # Measure recovery of sample-specific networks\n",
    "        W_test_pred = [c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "        f1s = get_f1s(W_test, W_test_pred, threshs)\n",
    "        W_test_pred_lr = [lr_c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "        f1s_lr = get_f1s(W_test, W_test_pred_lr, threshs)\n",
    "        print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                     data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                      model_params[\"k\"]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_baseline]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_notears]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lioness]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lr]), file=out_file)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### New Convex Case with Pickle Files  \n",
    "\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/c_notears_paramsweepRealConv.csv\", 'w') as out_file:\n",
    "    print(\"n\\tn_edges\\tn_c\\tcontext_snr\\tk_true\\tk\", end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"base_{:.3f}\".format(x) for x in threshs]), end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lioness_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"c_notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lr_c_notears_{:.3f}\".format(x) for x in threshs]), file=out_file)\n",
    "    \n",
    "    for arch in range(2, 16):  #number of archetypes\n",
    "        '''\n",
    "        data_params = {\n",
    "    \"n\": 100,    # number of DAGs\n",
    "    \"n_i\": 1,     # number of samples per DAG\n",
    "    \"d\" : 16,       # number of vertices in each DAG\n",
    "    \"n_edges\": 4,     # expected number of edges in each DAG\n",
    "    \"n_c\": 8,    # number of contextual features\n",
    "    \"use_archetypes\": True,\n",
    "    \"ensure_convex\" : False, # should the archetype be generated such that they form a convex set of DAGs?\n",
    "    \"k_true\" : arch,       # number of true archetypes\n",
    "    \"graph_type\": \"ER\",\n",
    "    'sem_type' : 'gauss',\n",
    "    'context_snr' : 1.0, # signal-to-noise ratio of the contextual data\n",
    "    \"n_mix\": 2\n",
    "}\n",
    "        \n",
    "    ##### This is where the blocked comments began. \n",
    "    ##### THIS IS WHERE I BEGIN MASSIVE INDENT  ##################\n",
    "    \n",
    "        W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "        '''\n",
    "        W_str = 'Wconv' + str(arch) + '.p'\n",
    "        C_str = 'Cconv' + str(arch) + '.p'\n",
    "        X_str = 'Xconv' + str(arch) + '.p'\n",
    "        W_dictStr = 'W_dictconv' + str(arch) + '.p'\n",
    "        C_dictStr = 'C_dictconv' + str(arch) + '.p' \n",
    "        W = pickle.load(open(W_str, 'rb'))\n",
    "        C = pickle.load(open(C_str, 'rb'))\n",
    "        X = pickle.load(open(X_str, 'rb'))\n",
    "        W_dict = pickle.load(open(W_dictStr, 'rb'))\n",
    "        C_dict = pickle.load(open(C_dictStr, 'rb'))\n",
    "\n",
    "        ####### THIS IS ALL OF THE LIONESS STUFF.  #######\n",
    "        ###### Make sure that the squeeze and split is consistent across models  ########\n",
    "\n",
    "        ####### I am moving all of this squeezing and unsqueezing and Dataframing South Of the Split  #######\n",
    "\n",
    "\n",
    "\n",
    "        C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "\n",
    "        ##### # Start Copy From Above   ######\n",
    "        X = np.squeeze(X)\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "        #print(X)\n",
    "\n",
    "        C = pd.DataFrame(C)\n",
    "        ####### # End Copy From Above\n",
    "        print(\"this should all be the same as before\")\n",
    "        #assert False\n",
    "\n",
    "\n",
    "        C_test =pd.DataFrame(C_test)   # I think this is where the hitch was \n",
    "        index = C_test.index\n",
    "        a_list = list(index)\n",
    "        print(a_list)\n",
    "\n",
    "\n",
    "\n",
    "        ##### this is all from test_lioness   ########\n",
    "        ppi            ='puma/ToyData/ToyPPIData.txt'\n",
    "        motif          ='puma/ToyData/ToyMotifData.txt'\n",
    "        expression_data='puma/ToyData/ToyExpressionData.txt'\n",
    "        lioness_file   ='Travis'\n",
    "        rm_missing     =False\n",
    "        output_file    ='panda.npy'\n",
    "        gt_file        ='panda/test_panda.txt'\n",
    "        #panda_obj      =Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "        #                  keep_expression_matrix=bool(lioness_file), modeProcess='legacy', save_memory=False)\n",
    "        # Set parameters\n",
    "        #lioness_obj = Lioness(panda_obj, start=1, end=1)\n",
    "        #lioness_obj = Lioness(panda_obj, data_params, C_train, X_train, start=1, end=1)\n",
    "        #lioness_obj.save_lioness_results(lioness_file)\n",
    "        # Read first lioness network\n",
    "        #res  = np.load('lioness_output/lioness.1.npy')\n",
    "        #gt = np.load('lioness/lioness.1.npy')\n",
    "        # Compare to ground truth\n",
    "        #assert(np.allclose(gt,res))\n",
    "\n",
    "        #2. Testing Lioness with motif set to None to compute Lioness on coexpression networks\n",
    "        motif          = None\n",
    "        # Make sure to keep epxression matrix for next step\n",
    "        panda_obj      = Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "                          keep_expression_matrix=True, modeProcess='legacy')\n",
    "        lioness_obj    = Lioness(panda_obj, data_params, X, a_list, start=1, end=1)\n",
    ")\n",
    "        lioness_obj.save_lioness_results(lioness_file)\n",
    "        # Read first lioness network\n",
    "        res  = np.load('lioness_output/lioness.1.npy')\n",
    "        gt   = np.load('lioness/lionessCoexpression.1.npy')\n",
    "        W_OGLioness = pickle.load(open('lionessParams.pkl', 'rb'))\n",
    "\n",
    "        W_OGLioness = np.array(W_OGLioness)\n",
    "\n",
    "\n",
    "\n",
    "        ##### This is where the block comments ended\n",
    "\n",
    "\n",
    "\n",
    "        #W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "        #C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "\n",
    "        notears = NOTEARS({'l1': 1e-3, 'alpha': 1e2, 'rho':1e1, 'gamma':1e1},\n",
    "                         (data_params[\"n_c\"], 1),\n",
    "                         (data_params[\"d\"], data_params[\"d\"]))\n",
    "        print(\"Fitting Population Model...\")\n",
    "        notears.fit(C_train, X_train, epochs=10, batch_size=1)\n",
    "        print(\"Finished Fitting Population Model.\")\n",
    "        pop_model = notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze()\n",
    "\n",
    "\n",
    "        def not_i(ar, i):\n",
    "            if i == 0:\n",
    "                return ar[1:]\n",
    "            if i == len(ar) - 1:\n",
    "                return ar[:-1]\n",
    "            return np.vstack((ar[:i], ar[i+1:]))\n",
    "        def lioness():\n",
    "            results = []\n",
    "            for i in range(data_params[\"n\"]):\n",
    "                print(\"{} / {}\".format(i, data_params['n']), end='\\r')\n",
    "                notears.model.set_weights([pop_model]) # initialize at pop model\n",
    "                notears.fit(not_i(C_train, i), not_i(X_train, i), epochs=3, batch_size=1, verbose=0)\n",
    "                results.append((data_params[\"n\"]-1)*(\n",
    "                    notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze() - pop_model))\n",
    "            return results\n",
    "        #print(\"Fitting LIONESS...\")\n",
    "        #W_lioness = lioness()\n",
    "        #print(\"Finished fitting LIONESS.\")\n",
    "        f1s_lioness   = get_f1s(W_test, W_OGLioness, threshs)\n",
    "        f1s_baseline = get_f1s(W_test, np.ones_like(W_test), threshs)\n",
    "        C_test = C_test.to_numpy() \n",
    "        f1s_notears  = get_f1s(W_test, [notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test], threshs)\n",
    "\n",
    "\n",
    "\n",
    "        rank = 5\n",
    "        for k in range(1, 20):\n",
    "            print(\"k={}\".format(k), end='\\r')\n",
    "            model_params = {\n",
    "                \"k\": k,     # Learned archetype dictionary size\n",
    "                \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "                \"encoder_output_shape\": (k,),\n",
    "                \"dict_shape\": (k, data_params[\"d\"], data_params[\"d\"]),\n",
    "                \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "                \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "                \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "                \"learning_rate\": 1e-3\n",
    "            }\n",
    "            print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                         data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                          model_params[\"k\"]), end='\\t')\n",
    "\n",
    "            lr_model_params = {\n",
    "                \"k\": k,     # Learned archetype dictionary size\n",
    "                \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "                \"encoder_output_shape\": (k,),\n",
    "                \"dict_shape\": (k, data_params[\"d\"], rank),\n",
    "                \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "                \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "                \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "                \"learning_rate\": 1e-3\n",
    "            }\n",
    "            lr_c_notears = LRContextualNOTEARS(lr_model_params[\"encoder_input_shape\"],\n",
    "                                          lr_model_params[\"encoder_output_shape\"],\n",
    "                                          lr_model_params[\"dict_shape\"],\n",
    "                                         lr_model_params[\"sample_specific_loss_params\"],\n",
    "                                         lr_model_params[\"archetype_loss_params\"],\n",
    "                                         lr_model_params[\"learning_rate\"])\n",
    "            lr_c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "            c_notears = ContextualNOTEARS(model_params[\"encoder_input_shape\"],\n",
    "                                          model_params[\"encoder_output_shape\"],\n",
    "                                          model_params[\"dict_shape\"],\n",
    "                                         model_params[\"sample_specific_loss_params\"],\n",
    "                                         model_params[\"archetype_loss_params\"],\n",
    "                                         model_params[\"learning_rate\"])\n",
    "            c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "            # Measure recovery of sample-specific networks\n",
    "            W_test_pred = [c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "            f1s = get_f1s(W_test, W_test_pred, threshs)\n",
    "            W_test_pred_lr = [lr_c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "            f1s_lr = get_f1s(W_test, W_test_pred_lr, threshs)\n",
    "            print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                         data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                          model_params[\"k\"]), end='\\t', file=out_file)\n",
    "            print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_baseline]), end='\\t', file=out_file)\n",
    "            print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_notears]), end='\\t', file=out_file)\n",
    "            print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lioness]), end='\\t', file=out_file)\n",
    "            print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s]), end='\\t', file=out_file)\n",
    "            print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lr]), file=out_file)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######  CONVEX CASE   ##########\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/c_notears_paramsweepNonConv.csv\", 'w') as out_file:\n",
    "    print(\"n\\tn_edges\\tn_c\\tcontext_snr\\tk_true\\tk\", end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"base_{:.3f}\".format(x) for x in threshs]), end=\"\\t\", file=out_file)\n",
    "    print(\"\\t\".join([\"notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lioness_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"c_notears_{:.3f}\".format(x) for x in threshs]), end='\\t', file=out_file)\n",
    "    print(\"\\t\".join([\"lr_c_notears_{:.3f}\".format(x) for x in threshs]), file=out_file)\n",
    "    \n",
    "    for arch in range(15, 30):  #number of archetypes\n",
    "        data_params = {\n",
    "    \"n\": 100,    # number of DAGs\n",
    "    \"n_i\": 1,     # number of samples per DAG\n",
    "    \"d\" : 16,       # number of vertices in each DAG\n",
    "    \"n_edges\": 4,     # expected number of edges in each DAG\n",
    "    \"n_c\": 8,    # number of contextual features\n",
    "    \"use_archetypes\": True,\n",
    "    \"ensure_convex\" : True, # should the archetype be generated such that they form a convex set of DAGs?\n",
    "    \"k_true\" : arch,       # number of true archetypes\n",
    "    \"graph_type\": \"ER\",\n",
    "    'sem_type' : 'gauss',\n",
    "    'context_snr' : 1.0, # signal-to-noise ratio of the contextual data\n",
    "    \"n_mix\": 2\n",
    "}\n",
    "        \n",
    "    ##### This is where the blocked comments began.      \n",
    "        W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "        W_str = 'Wconv' + str(arch) + '.p'\n",
    "        C_str = 'Cconv' + str(arch) + '.p'\n",
    "        X_str = 'Xconv' + str(arch) + '.p'\n",
    "        W_dictStr = 'W_dictconv' + str(arch) + '.p'\n",
    "        C_dictStr = 'C_dictconv' + str(arch) + '.p'\n",
    "\n",
    "\n",
    "        pickle.dump(W, open(W_str, 'wb'))\n",
    "        pickle.dump(C, open(C_str, 'wb'))\n",
    "        pickle.dump(X, open(X_str, 'wb'))\n",
    "        pickle.dump(W_dict, open(W_dictStr, 'wb'))\n",
    "        pickle.dump(C_dict, open(C_dictStr, 'wb'))\n",
    "        print(\"got through one\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"got through gen data\")\n",
    "    \n",
    "    ####### THIS IS ALL OF THE LIONESS STUFF.  #######\n",
    "    ###### Make sure that the squeeze and split is consistent across models  ########\n",
    "    \n",
    "    ####### I am moving all of this squeezing and unsqueezing and Dataframing South Of the Split  #######\n",
    "    #print(X.shape)\n",
    "    #X = np.squeeze(X)\n",
    "    #X = pd.DataFrame(X)\n",
    "    \n",
    "    #print(X)\n",
    "    \n",
    "    #C = pd.DataFrame(C)\n",
    "    #print(\"did we get into this thing?\")\n",
    "    #assert False\n",
    "    #W = pd.DataFrame(W)   #1000 x 128 x 128\n",
    "    \n",
    "    \n",
    "    C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "    \n",
    "    ##### # Start Copy From Above   ######\n",
    "    X = np.squeeze(X)\n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    #print(X)\n",
    "    \n",
    "    C = pd.DataFrame(C)\n",
    "    ####### # End Copy From Above\n",
    "    print(\"this should all be the same as before\")\n",
    "    #assert False\n",
    "    \n",
    "    \n",
    "    C_test =pd.DataFrame(C_test)   # I think this is where the hitch was \n",
    "    index = C_test.index\n",
    "    a_list = list(index)\n",
    "    print(a_list)\n",
    "    \n",
    "    #print(C_train)\n",
    "    #print(C_train.shape)   #750 x 8    between 0.0 and 1.0\n",
    "    #print(\"it got here mofos\")\n",
    "    #print(W_test)   #centered around 0\n",
    "    #print(W_test.shape)   # (250, 128, 128)\n",
    "    #print(X_train)\n",
    "    #print(X_train.shape)    #(750, 1, 128)\n",
    "    #assert False\n",
    "    #X = np.squeeze(X)\n",
    "    #print(X.shape)\n",
    "    #assert False\n",
    "    #W_lioness = lioness()\n",
    "    #print(W_test)\n",
    "    #print(type(W_test))\n",
    "    #assert False\n",
    "    \n",
    "    ##### this is all from test_lioness   ########\n",
    "    ppi            ='puma/ToyData/ToyPPIData.txt'\n",
    "    motif          ='puma/ToyData/ToyMotifData.txt'\n",
    "    expression_data='puma/ToyData/ToyExpressionData.txt'\n",
    "    lioness_file   ='Travis'\n",
    "    rm_missing     =False\n",
    "    output_file    ='panda.npy'\n",
    "    gt_file        ='panda/test_panda.txt'\n",
    "    #panda_obj      =Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "    #                  keep_expression_matrix=bool(lioness_file), modeProcess='legacy', save_memory=False)\n",
    "    # Set parameters\n",
    "    #lioness_obj = Lioness(panda_obj, start=1, end=1)\n",
    "    #lioness_obj = Lioness(panda_obj, data_params, C_train, X_train, start=1, end=1)\n",
    "    #lioness_obj.save_lioness_results(lioness_file)\n",
    "    # Read first lioness network\n",
    "    #res  = np.load('lioness_output/lioness.1.npy')\n",
    "    #gt = np.load('lioness/lioness.1.npy')\n",
    "    # Compare to ground truth\n",
    "    #assert(np.allclose(gt,res))\n",
    "\n",
    "    #2. Testing Lioness with motif set to None to compute Lioness on coexpression networks\n",
    "    motif          = None\n",
    "    # Make sure to keep epxression matrix for next step\n",
    "    panda_obj      = Panda(expression_data, motif, ppi, save_tmp=True, remove_missing=rm_missing,\n",
    "                      keep_expression_matrix=True, modeProcess='legacy')\n",
    "    lioness_obj    = Lioness(panda_obj, data_params, X, a_list, start=1, end=1)\n",
    "    #lioness_obj    = Lioness(panda_obj, data_params, C_train, X_train, start=1, end=1)\n",
    "    lioness_obj.save_lioness_results(lioness_file)\n",
    "    # Read first lioness network\n",
    "    res  = np.load('lioness_output/lioness.1.npy')\n",
    "    gt   = np.load('lioness/lionessCoexpression.1.npy')\n",
    "    W_OGLioness = pickle.load(open('jigglydiggly.pkl', 'rb'))\n",
    "    \n",
    "    W_OGLioness = np.array(W_OGLioness)\n",
    "    print(\"let's see if we got this far\")\n",
    "    #assert False\n",
    "\n",
    "    \n",
    "    \n",
    "    ##### This is where the block comments ended\n",
    "        \n",
    "        \n",
    "    \n",
    "    #W, C, X, W_dict, C_dict = gen_data(data_params)\n",
    "    #C_train, C_test, X_train, X_test, W_train, W_test = train_test_split(C, X, W, test_size=0.25)\n",
    "    \n",
    "    notears = NOTEARS({'l1': 1e-3, 'alpha': 1e2, 'rho':1e1, 'gamma':1e1},\n",
    "                     (data_params[\"n_c\"], 1),\n",
    "                     (data_params[\"d\"], data_params[\"d\"]))\n",
    "    print(\"Fitting Population Model...\")\n",
    "    notears.fit(C_train, X_train, epochs=10, batch_size=1)\n",
    "    print(\"Finished Fitting Population Model.\")\n",
    "    pop_model = notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze()\n",
    "    \n",
    "    \n",
    "    def not_i(ar, i):\n",
    "        if i == 0:\n",
    "            return ar[1:]\n",
    "        if i == len(ar) - 1:\n",
    "            return ar[:-1]\n",
    "        return np.vstack((ar[:i], ar[i+1:]))\n",
    "    def lioness():\n",
    "        results = []\n",
    "        for i in range(data_params[\"n\"]):\n",
    "            print(\"{} / {}\".format(i, data_params['n']), end='\\r')\n",
    "            notears.model.set_weights([pop_model]) # initialize at pop model\n",
    "            notears.fit(not_i(C_train, i), not_i(X_train, i), epochs=3, batch_size=1, verbose=0)\n",
    "            results.append((data_params[\"n\"]-1)*(\n",
    "                notears.model.predict(np.expand_dims(C_train[0], 0)).squeeze() - pop_model))\n",
    "        return results\n",
    "    #print(\"Fitting LIONESS...\")\n",
    "    #W_lioness = lioness()\n",
    "    #print(\"Finished fitting LIONESS.\")\n",
    "    f1s_lioness   = get_f1s(W_test, W_OGLioness, threshs)\n",
    "    f1s_baseline = get_f1s(W_test, np.ones_like(W_test), threshs)\n",
    "    C_test = C_test.to_numpy() \n",
    "    f1s_notears  = get_f1s(W_test, [notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test], threshs)\n",
    "    \n",
    "    print(\"DDDDDIIIIIDDDD WE GET THROUGH THE F1 SCORES?\")\n",
    "\n",
    "    rank = 5\n",
    "    for k in range(1, 20):\n",
    "        print(\"k={}\".format(k), end='\\r')\n",
    "        model_params = {\n",
    "            \"k\": k,     # Learned archetype dictionary size\n",
    "            \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "            \"encoder_output_shape\": (k,),\n",
    "            \"dict_shape\": (k, data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "            \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "            \"learning_rate\": 1e-3\n",
    "        }\n",
    "        print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                     data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                      model_params[\"k\"]), end='\\t')\n",
    "\n",
    "        lr_model_params = {\n",
    "            \"k\": k,     # Learned archetype dictionary size\n",
    "            \"encoder_input_shape\": (data_params[\"n_c\"], 1),\n",
    "            \"encoder_output_shape\": (k,),\n",
    "            \"dict_shape\": (k, data_params[\"d\"], rank),\n",
    "            \"dict_output_shape\": (data_params[\"d\"], data_params[\"d\"]),\n",
    "            \"sample_specific_loss_params\": {'l1': 1e-3, 'alpha': 1e2, 'rho': 1e1, 'gamma': 1e1},\n",
    "            \"archetype_loss_params\": {'l1': 0, 'alpha': 0, 'rho': 0},\n",
    "            \"learning_rate\": 1e-3\n",
    "        }\n",
    "        lr_c_notears = LRContextualNOTEARS(lr_model_params[\"encoder_input_shape\"],\n",
    "                                      lr_model_params[\"encoder_output_shape\"],\n",
    "                                      lr_model_params[\"dict_shape\"],\n",
    "                                     lr_model_params[\"sample_specific_loss_params\"],\n",
    "                                     lr_model_params[\"archetype_loss_params\"],\n",
    "                                     lr_model_params[\"learning_rate\"])\n",
    "        lr_c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "        c_notears = ContextualNOTEARS(model_params[\"encoder_input_shape\"],\n",
    "                                      model_params[\"encoder_output_shape\"],\n",
    "                                      model_params[\"dict_shape\"],\n",
    "                                     model_params[\"sample_specific_loss_params\"],\n",
    "                                     model_params[\"archetype_loss_params\"],\n",
    "                                     model_params[\"learning_rate\"])\n",
    "        c_notears.fit(C_train, X_train, batch_size=1, epochs=50)\n",
    "\n",
    "        # Measure recovery of sample-specific networks\n",
    "        W_test_pred = [c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "        f1s = get_f1s(W_test, W_test_pred, threshs)\n",
    "        W_test_pred_lr = [lr_c_notears.model.predict(np.expand_dims(c, 0)).squeeze() for c in C_test]\n",
    "        f1s_lr = get_f1s(W_test, W_test_pred_lr, threshs)\n",
    "        print(\"{}\\t{}\\t{}\\t{:.3f}\\t{}\\t{}\".format(data_params[\"n\"], data_params[\"n_edges\"], data_params[\"n_c\"],\n",
    "                                     data_params[\"context_snr\"], data_params[\"k_true\"], \n",
    "                                      model_params[\"k\"]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_baseline]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_notears]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lioness]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s]), end='\\t', file=out_file)\n",
    "        print(\"\\t\".join([\"{:.3f}\".format(x) for x in f1s_lr]), file=out_file)\n",
    "        \n",
    "        \n",
    "print(\" ALLLL THROUGH CONVEX WOOHOO  \")\n",
    "assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/c_notears_paramsweep.csv\", header=0, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, thresh in enumerate(threshs):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.scatter(df['k'], df['base_{:.3f}'.format(thresh)], label='All 1s', color='black')\n",
    "    #plt.scatter(df['k'], df['notears_{:.3f}'.format(thresh)], label='NOTEARS', color='blue')\n",
    "    #plt.axhline(f1s_base[i], label='All 1s')\n",
    "    plt.axhline(f1s_notears[i], linestyle='--', color='orange', label='NOTEARS')\n",
    "    plt.axhline(f1s_lioness[i], linestyle='--', color='purple', label='LIONESS')\n",
    "    #plt.scatter(df['k'], df['lioness_{:.3f}'.format(lioness)], label='LIONESS', color='orange')\n",
    "    plt.scatter(df['k'], df['c_notears_{:.3f}'.format(thresh)], label='C-NOTEARS', color='red')\n",
    "    plt.scatter(df['k'], df['lr_c_notears_{:.3f}'.format(thresh)], label='LR-C-NOTEARS', color='blue')\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xlabel(\"K\", fontsize=28)\n",
    "    plt.ylabel(\"Mean F1-Score of SS Networks\", fontsize=24)\n",
    "    plt.title(\"Thresholded at {}\".format(thresh), fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF archetypes exist,\n",
    "# Measure recovery of archetypes\n",
    "# TODO: Have to match up archetypes to dictionary, no guarantee of order.\n",
    "threshs = [0.0, 0.001, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "W_dict_pred = c_notears.explainer.trainable_variables[0].numpy()\n",
    "f1s_baseline = get_f1s(W_dict, np.ones_like(W_dict_pred), thresh)\n",
    "\n",
    "plt.plot(threshs, f1s)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1-Score of Archetype Edge Recovery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize a prediction\n",
    "#y_pred = trim_params(y_pred)\n",
    "#plt.imshow(utils.trim_params(w_test_pred[0]), cmap='coolwarm', vmin=-2, vmax=2)\n",
    "plt.imshow(w_test_pred[0], cmap='coolwarm', vmin=-2, vmax=2)\n",
    "plt.title(r\"$W_{i=185}$ Predicted\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(w_test[0], cmap='coolwarm', vmin=-2, vmax=2)\n",
    "plt.title(r\"$W_{i=185}$ Truth\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print data shapes and visualize true archetypes\n",
    "print(f\"subtypes {subtypes.shape}, W_n {W_n.shape}, c_n {c_n.shape}, X_n {X_n.shape}\")\n",
    "for i in range(len(W_k)):\n",
    "    print(f\"true archetype {i}\")\n",
    "    plt.imshow(W_k[i], cmap='coolwarm', vmin=-2, vmax=2)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the learned archetypes\n",
    "W_k_pred = c_notears.explainer.trainable_variables[0].numpy()\n",
    "for i in range(k):\n",
    "    print(f\"pred {i}\")\n",
    "    plt.imshow(W_k_pred[i], cmap='coolwarm', vmin=-2, vmax=2)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "for i in range(k):\n",
    "    print(f\"true {i}\")\n",
    "    plt.imshow(W_k[i], cmap='coolwarm', vmin=-2, vmax=2)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the predicted subtype and real subtype\n",
    "encoder(e_n[999:2000]).numpy(), subtypes[999:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f1_mat(W_k[i], W_k_pred[i], 0.0, 0.2) for i in range(k)])\n",
    "print(np.mean([f1_mat(W_k[i], W_k_pred[i], 0.0, 0.2) for i in range(k)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W_k[0], cmap='coolwarm', vmin=-2, vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MSE of some test sample for validation\n",
    "y_pred = c_notears.model.predict(e_n[999:1000])\n",
    "y_true = W_n[999:1000][0]\n",
    "print(f\"mse| pred: {np.mean(np.sum(np.square(y_pred-y_true)))}, baseline: {np.mean(np.sum(np.square(np.zeros(y_pred.shape)-y_true)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
